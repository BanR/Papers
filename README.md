# papers/resources

###Generic:
- http://colah.github.io/
- https://adeshpande3.github.io/
- http://karpathy.github.io/
- http://www.deeplearningbook.org/
- [AndrewNg cs229](http://cs229.stanford.edu/materials.html)
- A Tutorial on Deep Learning [1](http://ai.stanford.edu/~quocle/tutorial1.pdf) & [2](http://ai.stanford.edu/~quocle/tutorial2.pdf)
- https://github.com/aleju/papers/tree/master/neural-nets
- https://github.com/kjw0612/awesome-rnn#image-generation
- https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap
- https://github.com/rushter/data-science-blogs
- https://github.com/josephmisiti/awesome-machine-learning
- [A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285v1.pdf)
- [Batch Normalization](https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b#.mjo2k7r6k)
- https://github.com/BVLC/caffe/tree/master/models
- [MCMC] (http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/)
- http://blog.shakirm.com/
- [Yes you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.wo4vqjw6i)



###Word Embeddings
1. [Deep Learning, NLP, and Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)
2. [Exploiting Similarities among Languages for Machine Translation](https://arxiv.org/pdf/1309.4168.pdf)
3. [Deep Sentence Embedding Using LSTM](https://arxiv.org/pdf/1502.06922v3.pdf)
4. [Distributed Representations of Sentences and Documents](http://cs.stanford.edu/~quocle/paragraph_vector.pdf)
5. [Natural Language Processing (almost) from Scratch](https://arxiv.org/pdf/1103.0398v1.pdf)
6. [word2vec Explained: Deriving Mikolov et al.â€™s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722v1.pdf)
7. [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)
8. [Neural Word Embedding as Implicit Matrix Factorization](https://levyomer.files.wordpress.com/2014/09/neural-word-embeddings-as-implicit-matrix-factorization.pdf)
9. [Word2Vec Tutorial-The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
10. [Word2Vec Resources](http://mccormickml.com/2016/04/27/word2vec-resources/#efficient-estimation-of-word-representations-in-vector-space)
11. [Glove](http://www-nlp.stanford.edu/pubs/glove.pdf)

###Infinite Mixture Models
1. http://blog.echen.me/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/
2. http://blog.datumbox.com/the-dirichlet-process-the-chinese-restaurant-process-and-other-representations/
3. http://web.science.mq.edu.au/~mjohnson/papers/Johnson11MLSS-talk-extras.pdf
4. [Graphical Models and Bayesian Networks](http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html)
4. Indian Buffet Process [1](http://cocosci.berkeley.edu/tom/papers/indianbuffet.pdf) [2](http://www.mit.edu/~ilkery/papers/IndianBuffetProcess.pdf)

###Tensorflow:
- [CS224d:TensorFlow Tutorial](http://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf)
- https://github.com/jtoy/awesome-tensorflow
- [TensorFlow Tutorial](https://github.com/alrojo/tensorflow-tutorial)
- https://jasdeep06.github.io/posts/getting-started-with-tensorflow/

